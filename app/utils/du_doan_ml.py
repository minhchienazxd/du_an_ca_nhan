# file: ml_predictor.py
import pandas as pd
from datetime import datetime, timedelta
from pymongo import MongoClient
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# import c√°c ph√¢n t√≠ch / helper t·ª´ module c·ªßa b·∫°n
from .phan_tich import (
    get_last_days,
    phan_tich_cau_ngang,
    phan_tich_cau_cheo,
    get_all_last_two_digits,
    phan_tich_lo_roi,
    extract_all_caps,
    get_cap_at_position,
)

def has_number_in_day(number_str, day_data):
    """Ki·ªÉm tra s·ªë c√≥ xu·∫•t hi·ªán trong k·∫øt qu·∫£ ng√†y ƒë√≥ kh√¥ng"""
    ketqua = day_data.get("ketqua", {})
    all_last_two = get_all_last_two_digits(ketqua)
    return number_str in all_last_two

def has_valid_ketqua(doc):
    """Ki·ªÉm tra xem document c√≥ k·∫øt qu·∫£ h·ª£p l·ªá kh√¥ng (kh√¥ng ch·ª©a '...' ho·∫∑c r·ªóng)"""
    if not doc or not doc.get("ketqua"):
        return False
    
    ketqua = doc.get("ketqua", {})
    
    # Ki·ªÉm tra xem c√≥ √≠t nh·∫•t m·ªôt gi·∫£i c√≥ d·ªØ li·ªáu h·ª£p l·ªá kh√¥ng
    for values in ketqua.values():
        if isinstance(values, list):
            for v in values:
                # Ki·ªÉm tra n·∫øu gi√° tr·ªã kh√¥ng r·ªóng, kh√¥ng ph·∫£i "...", v√† c√≥ ƒë·ªô d√†i >= 2
                if v and v != "..." and len(v) >= 2 and v.strip():
                    return True
        else:
            # Ki·ªÉm tra gi√° tr·ªã ƒë∆°n
            if values and values != "..." and len(values) >= 2 and values.strip():
                return True
    return False

def get_training_data(data):
    """
    L·ªçc ch·ªâ nh·ªØng ng√†y c√≥ k·∫øt qu·∫£ h·ª£p l·ªá ƒë·ªÉ training
    Tr·∫£ v·ªÅ: danh s√°ch c√°c ng√†y ƒë√£ c√≥ k·∫øt qu·∫£
    """
    valid_data = [d for d in data if has_valid_ketqua(d)]
    print(f"üìä D·ªØ li·ªáu training: {len(valid_data)}/{len(data)} ng√†y c√≥ k·∫øt qu·∫£ h·ª£p l·ªá")
    
    # In ra c√°c ng√†y c√≥ k·∫øt qu·∫£ ƒë·ªÉ debug
    if valid_data:
        dates = [d["date"] for d in valid_data]
        print(f"üìÖ C√°c ng√†y c√≥ k·∫øt qu·∫£: {dates}")
    
    return valid_data

def get_prediction_date(training_data):
    """
    X√°c ƒë·ªãnh ng√†y c·∫ßn d·ª± ƒëo√°n d·ª±a tr√™n d·ªØ li·ªáu training
    """
    if not training_data:
        return None
    
    last_training_date = training_data[-1]["date"]
    last_date_obj = training_data[-1]["date_obj"]
    
    # Ng√†y d·ª± ƒëo√°n l√† ng√†y ti·∫øp theo sau ng√†y cu·ªëi c√πng c√≥ k·∫øt qu·∫£
    predict_date = (last_date_obj + timedelta(days=1)).strftime("%d-%m-%Y")
    
    print(f"üéØ D·ª± ƒëo√°n: {last_training_date} ‚Üí {predict_date}")
    return predict_date

def safe_int(s, default=0):
    try:
        return int(s)
    except:
        return default

def build_features_and_label(collection, so_ngay=30):
    """
    Sinh feature n√¢ng cao cho 00-99 d·ª±a tr√™n so_ngay ng√†y g·∫ßn nh·∫•t.
    Tr·∫£ v·ªÅ: df_train, df_predict, predict_date
    """
    # L·∫•y d·ªØ li·ªáu th√¥
    raw_data = get_last_days(collection, so_ngay)
    raw_data = [d for d in raw_data if d.get("date_obj")]
    raw_data.sort(key=lambda x: x["date_obj"])  # t·ª´ c≈© -> m·ªõi

    print(f"üì¶ D·ªØ li·ªáu th√¥: {len(raw_data)} ng√†y")
    
    # CH·ªà d√πng ng√†y c√≥ k·∫øt qu·∫£ h·ª£p l·ªá ƒë·ªÉ training
    training_data = get_training_data(raw_data)
    
    if len(training_data) < 8:
        print("‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ build features (c·∫ßn >=8 ng√†y c√≥ k·∫øt qu·∫£).")
        return pd.DataFrame(), pd.DataFrame(), None

    # X√°c ƒë·ªãnh ng√†y c·∫ßn d·ª± ƒëo√°n
    predict_date = get_prediction_date(training_data)
    if not predict_date:
        print("‚ùå Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ng√†y d·ª± ƒëo√°n")
        return pd.DataFrame(), pd.DataFrame(), None

    # Precompute expensive analyses ONCE (d√πng ƒë·ªÉ c√°c feature l√¥ r∆°i / t·ªïng quan n·∫øu c·∫ßn)
    try:
        lo_roi_analysis = phan_tich_lo_roi(collection, so_ngay=so_ngay) or {}
    except Exception as e:
        print("‚ö†Ô∏è L·ªói khi ch·∫°y phan_tich_lo_roi:", e)
        lo_roi_analysis = {}

    all_rows = []
    # Build training samples. For each day i (t·ª´ th·ª© 7 tr·ªü ƒëi), label l√† ng√†y i+1
    # CH·ªà d√πng training_data (ƒë√£ c√≥ k·∫øt qu·∫£)
    for i in range(7, len(training_data) - 1):
        cur_doc = training_data[i]
        next_doc = training_data[i + 1]
        current_date = cur_doc["date"]
        next_date = next_doc["date"]

        # S·ª¨A: previous days ph·∫£i l·∫•y t·ª´ training_data, kh√¥ng ph·∫£i raw_data
        previous_7_days = training_data[i - 7:i]
        previous_14_days = training_data[i - 14:i] if i >= 14 else training_data[max(0, i-14):i]
        previous_30_days = training_data[:i]

        # chu·∫©n b·ªã c√°c caps/positions t·ª´ ng√†y current ƒë·ªÉ ki·ªÉm tra ngang/ch√©o sang next
        # S·ª¨A: ch·ªâ d√πng training_data ƒë·ªÉ ph√¢n t√≠ch c·∫ßu
        analysis_data = training_data[max(0, i-7):i+2]
        cau_ngang_results = phan_tich_cau_ngang(analysis_data)
        cau_cheo_results = phan_tich_cau_cheo(analysis_data)

        for n in range(100):
            number_str = f"{n:02d}"

            # BASIC
            freq_7days = sum(1 for d in previous_7_days if has_number_in_day(number_str, d))
            freq_prev_day = 1 if previous_7_days and has_number_in_day(number_str, previous_7_days[-1]) else 0

            # === compute is_cau_ngang and cau_ngang_strength using prev_caps -> next_doc ===
            is_ngang = 0
            cau_ngang_strength = 0
            for c in cau_ngang_results:
                if c.get("final") == number_str:
                    is_ngang = 1
                    cau_ngang_strength = len(c.get("history", []))
                    break

            # === compute is_cau_cheo and cau_cheo_strength using cross pairs from prev_doc -> next_doc ===
            is_cheo = 0
            cau_cheo_strength = 0
            if isinstance(cau_cheo_results, dict):
                for cap_so, caus in cau_cheo_results.items():
                    if cap_so == number_str:
                        is_cheo = 1
                        cau_cheo_strength = len(caus)
                        break
            else:
                for c in cau_cheo_results:
                    if c.get("final") == number_str:
                        is_cheo = 1
                        cau_cheo_strength = len(c.get("history", []))
                        break
            
            in_any_cau = 1 if (is_ngang or is_cheo) else 0

            # ADVANCED FREQUENCIES
            freq_3days = sum(1 for d in previous_7_days[-3:] if has_number_in_day(number_str, d))
            freq_14days = sum(1 for d in previous_14_days if has_number_in_day(number_str, d))
            freq_30days = sum(1 for d in previous_30_days if has_number_in_day(number_str, d))
            freq_ratio_7days = freq_7days / 7.0
            freq_ratio_30days = freq_30days / len(previous_30_days) if previous_30_days else 0.0

            # APPEARANCE HISTORY on previous_30_days
            appearance_indices = []
            for idx, dd in enumerate(previous_30_days):
                if has_number_in_day(number_str, dd):
                    appearance_indices.append(idx)

            if len(appearance_indices) >= 2:
                gaps = [appearance_indices[j] - appearance_indices[j - 1] for j in range(1, len(appearance_indices))]
                avg_gap = sum(gaps) / len(gaps)
                min_gap = min(gaps)
                max_gap = max(gaps)
                last_gap = gaps[-1] if gaps else len(previous_30_days)
                consecutive_count = sum(1 for g in gaps if g == 1)
            else:
                avg_gap = min_gap = max_gap = last_gap = len(previous_30_days)
                consecutive_count = 0

            days_since_last = (len(previous_30_days) - 1 - appearance_indices[-1]) if appearance_indices else len(previous_30_days)

            # LO ROI features
            is_lo_roi_ung_vien = 0
            lo_roi_ty_le = 0
            for uv in lo_roi_analysis.get("ung_vien", []):
                if uv.get("so") and uv.get("so") == number_str:
                    is_lo_roi_ung_vien = 1
                    lo_roi_ty_le = uv.get("ty_le", 0)
                    break
            days_since_roi_db = lo_roi_analysis.get("db", {}).get("last_gap", len(previous_30_days))
            days_since_roi_nhieu = lo_roi_analysis.get("nhieu_nhay", {}).get("last_gap", len(previous_30_days))

            # LABEL: c√≥ v·ªÅ ng√†y next_date kh√¥ng?
            label = 1 if has_number_in_day(number_str, next_doc) else 0

            row = {
                "current_date": current_date,
                "next_date": next_date,
                "number": number_str,
                # basic
                "freq_7days": freq_7days,
                "freq_prev_day": freq_prev_day,
                # advanced freq
                "freq_3days": freq_3days,
                "freq_14days": freq_14days,
                "freq_30days": freq_30days,
                "freq_ratio_7days": freq_ratio_7days,
                "freq_ratio_30days": freq_ratio_30days,
                # gaps / seq
                "avg_gap": avg_gap,
                "min_gap": min_gap,
                "max_gap": max_gap,
                "last_gap": last_gap,
                "consecutive_count": consecutive_count,
                "days_since_last": days_since_last,
                
                # cau
                "is_cau_ngang": is_ngang,
                "is_cau_cheo": is_cheo,
                "cau_ngang_strength": cau_ngang_strength,
                "cau_cheo_strength": cau_cheo_strength,
                "in_any_cau": in_any_cau,
                # lo roi
                "is_lo_roi_ung_vien": is_lo_roi_ung_vien,
                "lo_roi_ty_le": lo_roi_ty_le,
                "days_since_roi_db": days_since_roi_db,
                "days_since_roi_nhieu": days_since_roi_nhieu,
                # label
                "label": label,
            }

            all_rows.append(row)

    # Build predict set for prediction date
    # S·ª¨A: D√πng training_data (ƒë√£ c√≥ k·∫øt qu·∫£) ƒë·ªÉ build features cho prediction
    last_training_doc = training_data[-1]
    current_date_for_prediction = last_training_doc["date"]
    
    previous_7_days = training_data[-7:] if len(training_data) >= 7 else training_data
    previous_14_days = training_data[-14:] if len(training_data) >= 14 else training_data
    previous_30_days = training_data
    
    # S·ª¨A: Ph√¢n t√≠ch c·∫ßu ch·ªâ d√πng training_data
    cau_ngang_results = phan_tich_cau_ngang(training_data[-7:])
    cau_cheo_results = phan_tich_cau_cheo(training_data[-7:])
    
    predict_rows = []
    for n in range(100):
        number_str = f"{n:02d}"

        freq_7days = sum(1 for d in previous_7_days if has_number_in_day(number_str, d))
        freq_prev_day = 1 if previous_7_days and has_number_in_day(number_str, previous_7_days[-1]) else 0

        is_ngang = 0
        cau_ngang_strength = 0
        for c in cau_ngang_results:
            if c.get("final") == number_str:
                is_ngang = 1
                cau_ngang_strength = len(c.get("history", []))
                break

        is_cheo = 0
        cau_cheo_strength = 0
        if isinstance(cau_cheo_results, dict):
            for cap_so, caus in cau_cheo_results.items():
                if cap_so == number_str:
                    is_cheo = 1
                    cau_cheo_strength = len(caus)
                    break
        else:
            for c in cau_cheo_results:
                if c.get("final") == number_str:
                    is_cheo = 1
                    cau_cheo_strength = len(c.get("history", []))
                    break
        
        in_any_cau = 1 if (is_ngang or is_cheo) else 0
        
        freq_3days = sum(1 for d in previous_7_days[-3:] if has_number_in_day(number_str, d))
        freq_14days = sum(1 for d in previous_14_days if has_number_in_day(number_str, d))
        freq_30days = sum(1 for d in previous_30_days if has_number_in_day(number_str, d))
        freq_ratio_7days = freq_7days / 7.0
        freq_ratio_30days = freq_30days / len(previous_30_days) if previous_30_days else 0.0

        appearance_indices = []
        for idx, dd in enumerate(previous_30_days):
            if has_number_in_day(number_str, dd):
                appearance_indices.append(idx)
        if len(appearance_indices) >= 2:
            gaps = [appearance_indices[j] - appearance_indices[j - 1] for j in range(1, len(appearance_indices))]
            avg_gap = sum(gaps) / len(gaps)
            min_gap = min(gaps)
            max_gap = max(gaps)
            last_gap = gaps[-1] if gaps else len(previous_30_days)
            consecutive_count = sum(1 for g in gaps if g == 1)
        else:
            avg_gap = min_gap = max_gap = last_gap = len(previous_30_days)
            consecutive_count = 0
        days_since_last = (len(previous_30_days) - 1 - appearance_indices[-1]) if appearance_indices else len(previous_30_days)

        is_lo_roi_ung_vien = 0
        lo_roi_ty_le = 0
        for uv in lo_roi_analysis.get("ung_vien", []):
            if uv.get("so") and uv.get("so") == number_str:
                is_lo_roi_ung_vien = 1
                lo_roi_ty_le = uv.get("ty_le", 0)
                break
        days_since_roi_db = lo_roi_analysis.get("db", {}).get("last_gap", len(previous_30_days))
        days_since_roi_nhieu = lo_roi_analysis.get("nhieu_nhay", {}).get("last_gap", len(previous_30_days))

        predict_rows.append({
            "current_date": current_date_for_prediction,  # Ng√†y cu·ªëi c√πng c√≥ k·∫øt qu·∫£
            "next_date": predict_date,  # Ng√†y c·∫ßn d·ª± ƒëo√°n
            "number": number_str,
            "freq_7days": freq_7days,
            "freq_prev_day": freq_prev_day,
            "is_cau_ngang": is_ngang,
            "is_cau_cheo": is_cheo,
            "freq_3days": freq_3days,
            "freq_14days": freq_14days,
            "freq_30days": freq_30days,
            "freq_ratio_7days": freq_ratio_7days,
            "freq_ratio_30days": freq_ratio_30days,
            "avg_gap": avg_gap,
            "min_gap": min_gap,
            "max_gap": max_gap,
            "last_gap": last_gap,
            "consecutive_count": consecutive_count,
            "days_since_last": days_since_last,
            "cau_ngang_strength": cau_ngang_strength,
            "cau_cheo_strength": cau_cheo_strength,
            "in_any_cau": in_any_cau,
            "is_lo_roi_ung_vien": is_lo_roi_ung_vien,
            "lo_roi_ty_le": lo_roi_ty_le,
            "days_since_roi_db": days_since_roi_db,
            "days_since_roi_nhieu": days_since_roi_nhieu,
        })

    df_train = pd.DataFrame(all_rows)
    df_predict = pd.DataFrame(predict_rows)

    # Fill NaN / types
    df_train = df_train.infer_objects(copy=False).fillna(0)
    df_predict = df_predict.infer_objects(copy=False).fillna(0)

    # l∆∞u ra CSV ƒë·ªÉ b·∫°n inspect
    df_train.to_csv("train_samples.csv", index=False, encoding="utf-8")
    df_predict.to_csv("predict_samples.csv", index=False, encoding="utf-8")

    print(f"‚úÖ ƒê√£ t·∫°o {len(df_train)} samples train v·ªõi {len(df_train.columns)} features")
    print(f"‚úÖ ƒê√£ t·∫°o {len(df_predict)} samples predict ‚Äî predict_date = {predict_date}")
    print("‚úÖ ƒê√£ l∆∞u train_samples.csv v√† predict_samples.csv")

    return df_train, df_predict, predict_date

def du_doan_ml(collection, so_du_doan=10, so_ngay=30):
    """H√†m ƒë·ªÉ Flask g·ªçi d·ª± ƒëo√°n ML"""
    df_train, df_predict, predict_date = build_features_and_label(collection, so_ngay=so_ngay)

    if df_train.empty or df_predict.empty or predict_date is None:
        return {"error": "‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ train ho·∫∑c predict"}

    features = [
        "freq_7days", "freq_prev_day", "freq_3days", "freq_14days", "freq_30days",
        "freq_ratio_7days", "freq_ratio_30days",
        "avg_gap", "min_gap", "max_gap", "last_gap", "consecutive_count", "days_since_last",
        "is_cau_ngang", "is_cau_cheo", "cau_ngang_strength", "cau_cheo_strength", "in_any_cau",
        "is_lo_roi_ung_vien", "lo_roi_ty_le", "days_since_roi_db", "days_since_roi_nhieu",
    ]

    features = [f for f in features if f in df_train.columns and f in df_predict.columns]
    if not features:
        return {"error": "‚ùå Kh√¥ng c√≥ feature h·ª£p l·ªá ƒë·ªÉ train"}

    X_train = df_train[features].astype(float)
    y_train = df_train["label"].astype(int)
    X_pred = df_predict[features].astype(float)

    lr_pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500))
    rf_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))

    try:
        lr_pipeline.fit(X_train, y_train)
        rf_pipeline.fit(X_train, y_train)
    except Exception as e:
        return {"error": f"‚ùå L·ªói khi train model: {e}"}

    try:
        prob_lr = lr_pipeline.predict_proba(X_pred)[:, 1]
        prob_rf = rf_pipeline.predict_proba(X_pred)[:, 1]
    except Exception as e:
        return {"error": f"‚ùå L·ªói khi predict: {e}"}

    df_predict = df_predict.copy()
    df_predict["prob_lr"] = prob_lr
    df_predict["prob_rf"] = prob_rf
    df_predict["prob_avg"] = df_predict[["prob_lr", "prob_rf"]].mean(axis=1)

    df_result = df_predict.sort_values("prob_avg", ascending=False).reset_index(drop=True)
    top_k = df_result.head(so_du_doan)

    du_doan = []
    for _, row in top_k.iterrows():
        du_doan.append({"so": row["number"], "xac_suat": float(row["prob_avg"])})

    return {
        "predict_date": predict_date,
        "du_doan": du_doan
    }

def main():
    client = MongoClient("mongodb://localhost:27017/")
    db = client["admin"]
    collection = db["kq_xs"]

    print("‚öôÔ∏è L·∫•y d·ªØ li·ªáu v√† sinh feature...")
    res = du_doan_ml(collection, so_du_doan=10, so_ngay=30)
    if "error" in res:
        print(res["error"])
        return

    print(f"üîÆ D·ª± ƒëo√°n cho ng√†y {res['predict_date']}:")
    for item in res["du_doan"]:
        print(f"  - {item['so']}  (p={item['xac_suat']:.4f})")

if __name__ == "__main__":
    main()